[{"content":"Introduction Authentik is an open-source identity provider that can be used to manage authentication and authorization for your applications. In this guide, I will explain how to install Authentik in a Kubernetes cluster to secure applications.\nPrerequisites A Kubernetes cluster with Traefik installed. Helm package manager installed and has required permissions to install and manage resources in the cluster. Cloudflare account with your domain configured. Already configured Cloudflare tunnel to use Traefik Ingress Controller. Installation Guide Step 1: Generate Secrets Before we prepare the Helm chart values file, we need to create a secretKey for Authentik to sign the JWT tokens and create a password for PostgreSQL database.\nStep 1.1: Create a random Password for PostgreSQL sudo apt install -y pwgen pwgen -s 50 1 This command generates a secure random password for the PostgreSQL database. Make sure to save this password securely as it will be used in the next steps.\nStep 1.2: Create a secretKey for Authentik openssl rand 60 | base64 -w 0 This command generates a secure random secret key for Authentik to sign the JWT tokens. Save this key securely as well.\nStep 2: Prepare the Helm Chart Values File Create a file named authentik-values.yaml with the following content:\nPlease replace the placeholders for secrets and domain with the values you generated in the previous step.\nauthentik: secret_key: \u0026#34;PASTE_YOUR_GENERATED_SECRET\u0026#34; # This sends anonymous usage-data, stack traces on errors and # performance data to sentry.io, and is fully opt-in error_reporting: enabled: true postgresql: password: \u0026#34;PASTE_YOUR_GENERATED_POSTGRES_PASSWORD\u0026#34; server: ingress: # Specify kubernetes ingress controller class name ingressClassName: traefik enabled: true hosts: - authentik.yourdomain.com # Replace it with your domain postgresql: enabled: true auth: password: \u0026#34;PASTE_YOUR_GENERATED_POSTGRES_PASSWORD\u0026#34; redis: enabled: true Step 3: Install Authentik Chart using Helm Run the following command to install Authentik using Helm:\nhelm repo add authentik https://charts.goauthentik.io helm repo update helm install authentik authentik/authentik -f authentik-values.yaml --namespace authentik --create-namespace This command installs Authentik in the authentik namespace using the values specified in the authentik-values.yaml file.\nYou can check the status of the installation using:\nkubectl get all -n authentik Wait for the pods to be in the Running state before proceeding to the next step.\nStep 4: Verify the Installation In the values file, we specified the domain as authentik.yourdomain.com. By default, Ingress should be created for the Authentik service.\nYou can verify this by checking the Ingress:\nkubectl get ingress -n authentik You should see an Ingress for authentik.yourdomain.com. You can also check the Authentik service by accessing the URL in your browser:\nhttps://authentik.yourdomain.com After the installation is complete, access authentik at https://authentik.yourdomain.com/if/flow/initial-setup/. Here, you can set a password for the default akadmin user.\nOnce you set the password, you can log in to the Authentik dashboard using the akadmin user.\nHome page of Authentik dashboard will look like this:\nStep 5: Reset the akadmin Password If you need to reset the akadmin password, go to AdminInterface \u0026gt; UsersDetails, select the akadmin user, and click on the \u0026ldquo;Reset Password\u0026rdquo; button.\nIn the next blog post, I will explain how to configure Authentik to secure applications using ProxyProvider.\nConclusion In this guide, we have successfully installed Authentik in a Kubernetes cluster using Helm. We also verified the installation and set up the initial admin user.\nPlease check the below blog post to learn how to configure Authentik to secure applications using ProxyProvider.\n","permalink":"http://localhost:1313/posts/kubernetes/how-to-install-authentik-in-kubernetes-to-secure-applications/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003e\u003cimg alt=\"authentik-installation-blog.png\" loading=\"lazy\" src=\"/images/authentik-installation-blog.png\"\u003e\u003c/p\u003e\n\u003cp\u003eAuthentik is an open-source identity provider that can be used to manage authentication and authorization for your applications.\nIn this guide, I will explain how to install Authentik in a Kubernetes cluster to secure applications.\u003c/p\u003e\n\u003ch1 id=\"prerequisites\"\u003ePrerequisites\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eA Kubernetes cluster with Traefik installed.\u003c/li\u003e\n\u003cli\u003eHelm package manager installed and has required permissions to install and manage resources in the cluster.\u003c/li\u003e\n\u003cli\u003eCloudflare account with your domain configured.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.vijay-narayanan.com/posts/kubernetes/how-to-set-up-traefik-ingress-controller-in-kubernetes\"\u003eAlready configured Cloudflare tunnel to use Traefik Ingress Controller\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"installation-guide\"\u003eInstallation Guide\u003c/h1\u003e\n\u003ch2 id=\"step-1-generate-secrets\"\u003eStep 1: Generate Secrets\u003c/h2\u003e\n\u003cp\u003eBefore we prepare the Helm chart values file, we need to create a secretKey for Authentik to sign the JWT tokens and create a password for PostgreSQL database.\u003c/p\u003e","title":"How To Install Authentik In Kubernetes To Secure Applications"},{"content":"Introduction In this guide, we will explore how to secure public web applications running on Kubernetes using Authentik, a modern open-source identity provider. We will also leverage Cloudflare for additional security and performance enhancements. The setup will include Traefik as the ingress controller to manage incoming traffic to our applications.\nPrerequisites A Kubernetes cluster up and running. Helm installed for managing Kubernetes applications. Traefik installed as the ingress controller. Authentik installed in your Kubernetes cluster. Please check my previous posts for detailed instructions on how to set up Traefik and Authentik in Kubernetes.\nHow to Install Traefik in Kubernetes\nHow to Install Authentik in Kubernetes\nSetup Guide Step 1: Check your public web application Ensure that your public web application is accessible via Traefik. You can do this by creating a simple deployment and service in Kubernetes.\nkubectl create namespace nginx kubectl -n nginx create deployment nginx --image=nginx:alpine kubectl -n nginx expose deployment nginx --port 80 Create IngressRoute for the application:\n# nginx-ingressroute.yaml apiVersion: traefik.io/v1alpha1 kind: IngressRoute metadata: name: nginx namespace: nginx spec: entryPoints: - websecure routes: - kind: Rule match: Host(`nginx.yourdomain.com`) services: - name: nginx port: 80 Apply the IngressRoute:\nkubectl apply -f nginx-ingressroute.yaml Verify that the application is accessible via Traefik by visiting https://nginx.yourdomain.com.\nNow the problem is that anyone can access this application without any authentication. To secure this application, we will use Authentik to enforce authentication before allowing access.\nStep 2: Configure Authentik Step 2.1: Create a Provider Log in to your Authentik admin panel.\nGo to Providers and create a new provider. Choose ProxyProvider as the type.\nClick on Create and choose ProxyProvider:\nFill in the required details as below:\nEnter your desired name for the provider (e.g., \u0026ldquo;nginx-demo-application-provider\u0026rdquo;). Choose Authorization Flow as default-provider-authorization-explicit-consent (Authorize Application). Choose Forward auth(single application) option and enter the URL of your application (e.g., https://nginx.yourdomain.com). Finally, click on Finish to save the provider. Step 2.2: Create an Application Go to Applications and create a new application.\nEnter a name for the application (e.g., \u0026ldquo;My Secured Application\u0026rdquo;). Enter the slug for the application (e.g., \u0026ldquo;nginx-demo-application\u0026rdquo;). Choose the provider you created in the previous step. Expand the UI settings section and set the Launch URL to the URL of your application (e.g., https://nginx.yourdomain.com). Now the application is bind to the provider we created earlier, which will handle authentication.\nStep 2.3: Create an Outposts Go to Outposts and create a new outpost.\n!10-authentik-outposts-blade.png\nClick on Create and fill in the details as below:\nEnter a name for the outpost (e.g., \u0026ldquo;k8s-my-nginx-app-outpost\u0026rdquo;). Choose type as proxy. Keep the Integration type as Local Kubernetes Cluster. Now from the Selection Section, choose the application you created and move to the right side. Expand the Advanced Settings and change the object_naming_template value as same as the name of the outpost (e.g., k8s-my-nginx-app-outpost). Finally, click on Create to save the outpost. Now in your kubernetes cluster, within the authentik namespace, you will see a new deployment and service created for the outpost.\nWait for the outpost to be ready. You can check the status of the outpost in the Authentik admin panel under Outposts.\nThat\u0026rsquo;s it! You have successfully created an outpost in Authentik that will handle authentication for your application. The Next step is to configure Traefik to use this outpost for authentication.\nStep 3: Configure Traefik to use Authentik ","permalink":"http://localhost:1313/posts/kubernetes/how-to-secure-kubernetes-public-web-applications-using-authentik/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eIn this guide, we will explore how to secure public web applications running on Kubernetes using Authentik, a modern open-source identity provider.\nWe will also leverage Cloudflare for additional security and performance enhancements.\nThe setup will include Traefik as the ingress controller to manage incoming traffic to our applications.\u003c/p\u003e\n\u003ch1 id=\"prerequisites\"\u003ePrerequisites\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eA Kubernetes cluster up and running.\u003c/li\u003e\n\u003cli\u003eHelm installed for managing Kubernetes applications.\u003c/li\u003e\n\u003cli\u003eTraefik installed as the ingress controller.\u003c/li\u003e\n\u003cli\u003eAuthentik installed in your Kubernetes cluster.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePlease check my previous posts for detailed instructions on how to set up Traefik and Authentik in Kubernetes.\u003c/p\u003e","title":"How To Secure Kubernetes Public Web Applications Using Authentik"},{"content":"Introduction In this guide, I will explain how to securely expose the Traefik dashboard in a Kubernetes cluster using Cloudflare. The Traefik dashboard provides insights into the traffic and routing within your cluster, but it should be secured to prevent unauthorized access.\nPrerequisites A Kubernetes cluster with Traefik installed. Helm package manager installed and has required permissions to install and manage resources in the cluster. Cloudflare account with your domain configured. Already configured Cloudflare tunnel to use Traefik Ingress Controller. ","permalink":"http://localhost:1313/posts/kubernetes/how-to-securely-expose-traefik-dashboard-in-kubernetes/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eIn this guide, I will explain how to securely expose the Traefik dashboard in a Kubernetes cluster using Cloudflare.\nThe Traefik dashboard provides insights into the traffic and routing within your cluster, but it should be secured to prevent unauthorized access.\u003c/p\u003e\n\u003ch1 id=\"prerequisites\"\u003ePrerequisites\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eA Kubernetes cluster with Traefik installed.\u003c/li\u003e\n\u003cli\u003eHelm package manager installed and has required permissions to install and manage resources in the cluster.\u003c/li\u003e\n\u003cli\u003eCloudflare account with your domain configured.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.vijay-narayanan.com/posts/kubernetes/how-to-set-up-traefik-ingress-controller-in-kubernetes\"\u003eAlready configured Cloudflare tunnel to use Traefik Ingress Controller\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e","title":"How To Securely Expose Traefik Dashboard In Kubernetes"},{"content":"Introduction I am using Nginx Ingress Controller for my Kubernetes cluster, but I wanted to set up Traefik as well for specific use cases. This guide explains how I installed Traefik on my Kubernetes cluster using Helm.\nWhy I want to use Traefik I want to use authentication features for my applications, and my Nginx Ingress Controller setup requires enabling allow-snippet-annotations and setting annotations-risk-level to Critical. This is because Nginx Ingress Controller uses annotations for advanced configurations, which can be risky if not managed properly. Traefik, on the other hand, does not require such risky configurations and provides a safer way to manage ingress rules and features. So I decided to switch to Traefik as my primary Ingress Controller.\nPrerequisites A Kubernetes cluster (I am using a self-hosted cluster) Helm installed on your local machine Access to the Kubernetes cluster with sufficient permissions to install applications A domain name (I am using Cloudflare for DNS management) Setup Guide Step 1: Install Traefik using Helm To install Traefik on my Kubernetes cluster, I used the following Helm command:\nhelm repo add traefik https://traefik.github.io/charts helm repo update helm upgrade --install traefik traefik/traefik \\ --namespace traefik \\ --set ports.web.redirections.entryPoint.scheme=https \\ --set ports.web.redirections.entryPoint.permanent=true \\ --set ports.web.redirections.entryPoint.to=websecure \\ --set service.type=ClusterIP This command installs Traefik using Helm, a package manager for Kubernetes. It sets up Traefik in the traefik namespace and configures it to redirect HTTP traffic to HTTPS. The service type is set to ClusterIP, which means it will only be accessible within the cluster.\nTraefik Ports and Accessibility Port Purpose Accessibility 8000 HTTP (web) traffic Cluster-internal 8443 HTTPS (websecure) traffic Cluster-internal 9100 Metrics (monitoring) Cluster-internal 8080 Traefik dashboard and API By default Internally accessible only Step 2: Configure Cloudflare to use Traefik Since we enabled websecure in the Traefik installation, you need to configure your DNS and SSL settings to use HTTPS for your domain. In my case, I am using Cloudflare, so I will share the steps specific to Cloudflare below.\nStep 2.1: Install Cloudflare Tunnel sudo mkdir -p --mode=0755 /usr/share/keyrings curl -fsSL https://pkg.cloudflare.com/cloudflare-main.gpg | sudo tee /usr/share/keyrings/cloudflare-main.gpg \u0026gt;/dev/null echo \u0026#34;deb [signed-by=/usr/share/keyrings/cloudflare-main.gpg] https://pkg.cloudflare.com/cloudflared any main\u0026#34; | sudo tee /etc/apt/sources.list.d/cloudflared.list sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install cloudflared Step 2.2: Authenticate Cloudflare Tunnel sudo cloudflared tunnel login Don\u0026rsquo;t worry, if you see a login url in the server terminal, just copy it and paste it in your personal browser. After logging in, you will see a success message in the server terminal.\nStep 2.3: Create a Tunnel sudo cloudflared tunnel create \u0026lt;tunnel-name\u0026gt; Example:\nsudo cloudflared tunnel create traefik-ingress-tunnel Once the tunnel is created, you will see a message with the tunnel ID and a certificate file path.\nExample output:\nvijay@controlplane:~$ cloudflared tunnel create traefik-ingress-tunnel Tunnel credentials written to /root/.cloudflared/lmnop-0ce8-efgh-8c67-abcd.json. cloudflared chose this file based on where your origin certificate was found. Keep this file secret. To revoke these credentials, delete the tunnel. Created tunnel traefik-ingress-tunnel with id lmnop-0ce8-efgh-8c67-abcd You can check the list of tunnels created by running:\nsudo cloudflared tunnel list sudo cloudflared tunnel info traefik-ingress-tunnel Copy the tunnel ID and certificate file path for later use. I would recommend renaming the certificate file to something more meaningful, like traefik-ingress-tunnel-credential.json.\nsudo mkdir /home/vijay/.cloudflared \u0026amp;\u0026amp; sudo chown vijay:vijay /home/vijay/.cloudflared \u0026amp;\u0026amp; sudo chmod 700 /home/vijay/.cloudflared \u0026amp;\u0026amp; sudo chmod 600 /home/vijay/.cloudflared/* sudo cp /root/.cloudflared/lmnop-0ce8-efgh-8c67-abcd.json /home/vijay/.cloudflared/traefik-ingress-tunnel-credential.json Step 2.4: Create a Kubernetes Secret for Cloudflare Tunnel Credentials I am creating a secret in the cloudflare namespace, but you can create it in any namespace you prefer. Make sure to update the ConfigMap and Deployment accordingly. Feel free to change the path to the credential file if you have it in a different location.\nkubectl create namespace cloudflare kubectl -n cloudflare create secret generic cloudflared-creds \\ --from-file=traefik-ingress-tunnel-credential.json=/home/vijay/.cloudflared/traefik-ingress-tunnel-credential.json The next step is to create a ConfigMap with the Cloudflare Tunnel configuration.\nStep 2.5: Create a Kubernetes ConfigMap for Cloudflare Tunnel Since Cloudflare supports a single tunnel for multiple subdomains, you can use this setup to expose multiple applications without needing to create separate tunnels for each one. For example, any subdomain under *.yourdomain.com will be routed to the Traefik service in your cluster, allowing you to access your applications securely over HTTPS. Here is how to acheive that:\n# cloudflared-config.yaml apiVersion: v1 kind: ConfigMap metadata: name: cloudflared-config namespace: cloudflare data: config.yaml: | tunnel: traefik-ingress-tunnel credentials-file: /etc/cloudflared/creds/traefik-ingress-tunnel-credential.json ingress: - hostname: \u0026#39;*.yourdomain.com\u0026#39; originRequest: noTLSVerify: true service: https://traefik.traefik.svc.cluster.local:443 - service: http_status:404 Explanation:\ntunnel: The name of the tunnel you created. credentials-file: Don\u0026rsquo;t be confused with the path to the credential file, this is the path inside the container where the credential file will be mounted. ingress: This section defines the routing rules for the tunnel. hostname: The domain or subdomain you want to expose. Replace yourdomain.com with your actual domain. originRequest.noTLSVerify: Set to true to skip TLS verification for the service. service: The internal service URL that Cloudflare will route traffic. In this case, it points to the Traefik service in the traefik namespace working on port 443. http_status:404: This is a catch-all rule that returns a 404 status for any unmatched requests. Step 2.6: Create Deployment for Cloudflare Tunnel # cloudflared-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: cloudflared namespace: cloudflare spec: replicas: 1 selector: matchLabels: app: cloudflared template: metadata: labels: app: cloudflared spec: containers: - name: cloudflared image: cloudflare/cloudflared:2025.6.1 # check and use the latest version args: [\u0026#34;tunnel\u0026#34;, \u0026#34;--config\u0026#34;, \u0026#34;/etc/cloudflared/config.yaml\u0026#34;, \u0026#34;run\u0026#34;] volumeMounts: - name: config mountPath: /etc/cloudflared/config.yaml subPath: config.yaml - name: creds mountPath: /etc/cloudflared/creds volumes: - name: config configMap: name: cloudflared-config - name: creds secret: secretName: cloudflared-creds Explanation:\nargs: The command to run the Cloudflare Tunnel with the specified configuration file. volumeMounts: Mounts the ConfigMap and secret containing the Cloudflare Tunnel configuration and credentials. This is the path above ConfigMap uses /etc/cloudflared/creds/traefik-ingress-tunnel-credential.json. Step 2.7: Apply the ConfigMap and Deployment kubectl apply -f cloudflared-config.yaml kubectl apply -f cloudflared-deployment.yaml Make sure your Secret, ConfigMap, and Deployment are in the same namespace or adjust the commands accordingly. Otherwise, your Deployment won\u0026rsquo;t be able to access the ConfigMap and Secret.\nThat\u0026rsquo;s it! You have successfully set up Cloudflare Tunnel to route traffic to your Traefik Ingress Controller in your Kubernetes cluster.\nStep 2.8: CNAME Configuration in Cloudflare Go to your Cloudflare dashboard and navigate to the DNS settings for your domain. Create a CNAME record for the subdomain you want to expose, pointing it to *.yourdomain.com.\nIn the Target field, enter the tunnel-id.cfargotunnel.com Example: lmnop-0ce8-efgh-8c67-abcd.cfargotunnel.com\nWithout this step, the Cloudflare Tunnel won\u0026rsquo;t be able to route traffic to your application.\nStep 3: Verify the Setup with Sample Application Step 3.1: Deploy a Sample Nginx Application Let\u0026rsquo;s deploy nginx as a sample application to verify that everything is working correctly.\nkubectl create namespace nginx kubectl create deployment nginx --image=nginx:alpine --namespace=nginx kubectl expose deployment nginx --port=80 --target-port=80 --type=ClusterIP --name=nginx --namespace=nginx Verify that the nginx service is running:\nkubectl get all -n nginx You should see the nginx pod and service running in the nginx namespace.\nStep 3.2: Create Traefik IngressResource for Nginx # nginx-ingressroute.yaml apiVersion: traefik.io/v1alpha1 kind: IngressRoute metadata: name: nginx-ingress namespace: nginx spec: entryPoints: - websecure routes: - kind: Rule match: Host(`nginx.yourdomain.com`) services: - kind: Service name: nginx namespace: nginx port: 80 Apply the IngressRoute:\nkubectl apply -f nginx-ingressroute.yaml Step 3.3: Access the Nginx Application Now, you can access the nginx application using the domain you configured in the IngressRoute. Open your browser and navigate to https://nginx.yourdomain.com.\nIf everything is set up correctly, you should see the default Nginx welcome page.\nConclusion We configured Traefik as an Ingress Controller in our Kubernetes cluster and set up Cloudflare Tunnel to route traffic securely to our applications.\n","permalink":"http://localhost:1313/posts/kubernetes/how-to-set-up-traefik-ingress-controller-in-kubernetes/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eI am using Nginx Ingress Controller for my Kubernetes cluster, but I wanted to set up Traefik as well for specific use cases.\nThis guide explains how I installed Traefik on my Kubernetes cluster using Helm.\u003c/p\u003e\n\u003ch1 id=\"why-i-want-to-use-traefik\"\u003eWhy I want to use Traefik\u003c/h1\u003e\n\u003cp\u003eI want to use authentication features for my applications, and my Nginx Ingress Controller setup requires enabling \u003ccode\u003eallow-snippet-annotations\u003c/code\u003e and setting \u003ccode\u003eannotations-risk-level\u003c/code\u003e to Critical.\nThis is because Nginx Ingress Controller uses annotations for advanced configurations, which can be risky if not managed properly.\nTraefik, on the other hand, does not require such risky configurations and provides a safer way to manage ingress rules and features. So I decided to switch to Traefik as my primary Ingress Controller.\u003c/p\u003e","title":"How to set up Traefik Ingress Controller in Kubernetes"},{"content":"Introduction Containerd is a core component of Kubernetes that manages container lifecycle. Upgrading containerd can bring performance improvements, bug fixes, and new features. This guide will walk you through the steps to upgrade Containerd on a Kubernetes node.\nDeployment Script CURRENT_VERSION=\u0026#34;v2.1.3\u0026#34; ARCH=\u0026#34;linux-amd64\u0026#34; DOWNLOAD_URL=\u0026#34;https://github.com/containerd/containerd/releases/download/${CURRENT_VERSION}/containerd-${CURRENT_VERSION#v}-${ARCH}.tar.gz\u0026#34; echo \u0026#34;Draining node...\u0026#34; kubectl drain $(hostname) --ignore-daemonsets --delete-emptydir-data echo \u0026#34;Stopping containerd...\u0026#34; sudo systemctl stop containerd echo \u0026#34;Removing old containerd...\u0026#34; sudo apt remove -y containerd echo \u0026#34;Downloading containerd $CURRENT_VERSION...\u0026#34; wget -q $DOWNLOAD_URL -O containerd.tar.gz echo \u0026#34;Extracting and installing containerd...\u0026#34; tar -xvf containerd.tar.gz sudo cp bin/* /usr/local/bin/ echo \u0026#34;Setting up systemd service...\u0026#34; sudo systemctl unmask containerd sudo wget -q -O /etc/systemd/system/containerd.service https://raw.githubusercontent.com/containerd/containerd/main/containerd.service sudo systemctl daemon-reexec sudo systemctl daemon-reload sudo systemctl enable --now containerd echo \u0026#34;Generating config and setting SystemdCgroup...\u0026#34; sudo mkdir -p /etc/containerd sudo bash -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; sudo sed -i \u0026#39;s/SystemdCgroup = false/SystemdCgroup = true/\u0026#39; /etc/containerd/config.toml echo \u0026#34;Restarting containerd and kubelet...\u0026#34; sudo systemctl restart containerd sudo systemctl restart kubelet echo \u0026#34;Updated. Current containerd version:\u0026#34; containerd --version ","permalink":"http://localhost:1313/posts/kubernetes/how-to-upgrade-containerd-version-in-kubernetes/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eContainerd is a core component of Kubernetes that manages container lifecycle.\nUpgrading containerd can bring performance improvements, bug fixes, and new features.\nThis guide will walk you through the steps to upgrade Containerd on a Kubernetes node.\u003c/p\u003e\n\u003ch1 id=\"deployment-script\"\u003eDeployment Script\u003c/h1\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eCURRENT_VERSION\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;v2.1.3\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eARCH\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;linux-amd64\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nv\"\u003eDOWNLOAD_URL\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;https://github.com/containerd/containerd/releases/download/\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"nv\"\u003eCURRENT_VERSION\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e/containerd-\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"nv\"\u003eCURRENT_VERSION\u003c/span\u003e\u003cspan class=\"p\"\u003e#v\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e-\u003c/span\u003e\u003cspan class=\"si\"\u003e${\u003c/span\u003e\u003cspan class=\"nv\"\u003eARCH\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e.tar.gz\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Draining node...\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekubectl drain \u003cspan class=\"k\"\u003e$(\u003c/span\u003ehostname\u003cspan class=\"k\"\u003e)\u003c/span\u003e --ignore-daemonsets --delete-emptydir-data\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Stopping containerd...\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo systemctl stop containerd\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Removing old containerd...\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo apt remove -y containerd\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Downloading containerd \u003c/span\u003e\u003cspan class=\"nv\"\u003e$CURRENT_VERSION\u003c/span\u003e\u003cspan class=\"s2\"\u003e...\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ewget -q \u003cspan class=\"nv\"\u003e$DOWNLOAD_URL\u003c/span\u003e -O containerd.tar.gz\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Extracting and installing containerd...\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003etar -xvf containerd.tar.gz\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo cp bin/* /usr/local/bin/\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Setting up systemd service...\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo systemctl unmask containerd\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo wget -q -O /etc/systemd/system/containerd.service https://raw.githubusercontent.com/containerd/containerd/main/containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo systemctl daemon-reexec\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo systemctl daemon-reload\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo systemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Generating config and setting SystemdCgroup...\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo mkdir -p /etc/containerd\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo bash -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sed -i \u003cspan class=\"s1\"\u003e\u0026#39;s/SystemdCgroup = false/SystemdCgroup = true/\u0026#39;\u003c/span\u003e /etc/containerd/config.toml\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Restarting containerd and kubelet...\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo systemctl restart containerd\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo systemctl restart kubelet\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Updated. Current containerd version:\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003econtainerd --version\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"How To Upgrade Containerd version in Kubernetes"},{"content":"Introduction In this guide, I will walk through the process of self-hosting JetBrains YouTrack, a powerful project management tool, in a Kubernetes environment. YouTrack is designed to help teams manage their projects efficiently with features like issue tracking, agile boards, and customizable workflows. It is also free for up to 10 users, making it an excellent choice for small teams or personal projects.\nPrerequisites Before we begin, ensure you have the following prerequisites:\nA Kubernetes cluster up and running (not applicable for cloud providers like GKE, EKS, or AKS). Storage Class configured in your cluster. In this guide, I will use the longhorn storage class. To securely access the YouTrack instance, I will use Nginx Ingress Controller with Cloudflare Tunnel (Argo Tunnel) for secure access. A domain name that registers with Cloudflare. Deployment Steps Step 1: Create a Namespace Create a dedicated namespace for YouTrack to keep resources organized:\nkubectl create namespace youtrack Step 2: Create a Persistent Volume Claim Create a Persistent Volume Claim (PVC) to store YouTrack data. This ensures that your data persists even if the pod is deleted or recreated.\nFor more information on how to create a PVC, refer to the Kubernetes documentation. To know more about the Longhorn storage class, refer to the Longhorn documentation.\nWe are going to create four PVCs for different purposes:\nyoutrack-data-pv-claim: For YouTrack application data. youtrack-conf-pv-claim: For YouTrack configuration files. youtrack-logs-pv-claim: For YouTrack logs. youtrack-backups-pv-claim: For YouTrack backups. # youtrack-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: youtrack-data-pv-claim namespace: youtrack spec: accessModes: - ReadWriteOnce storageClassName: longhorn resources: requests: storage: 5Gi --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: youtrack-conf-pv-claim namespace: youtrack spec: accessModes: - ReadWriteOnce storageClassName: longhorn resources: requests: storage: 1Gi --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: youtrack-logs-pv-claim namespace: youtrack spec: accessModes: - ReadWriteOnce storageClassName: longhorn resources: requests: storage: 1Gi --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: youtrack-backups-pv-claim namespace: youtrack spec: accessModes: - ReadWriteOnce storageClassName: longhorn resources: requests: storage: 2Gi Apply the PVCs:\nkubectl apply -f youtrack-pvc.yaml Step 3: Create a Deployment and Mount the PVCs Create a Deployment for YouTrack. This deployment will use the official YouTrack Docker image and mount the PVCs created in the previous step.\n# youtrack-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: youtrack-deployment namespace: youtrack labels: app: youtrack spec: replicas: 1 selector: matchLabels: app: youtrack template: metadata: labels: app: youtrack spec: securityContext: runAsUser: 0 runAsGroup: 0 containers: - name: youtrack image: jetbrains/youtrack:2025.1.82518 volumeMounts: - name: opt-youtrack-data mountPath: /opt/youtrack/data - name: opt-youtrack-conf mountPath: /opt/youtrack/conf - name: opt-youtrack-logs mountPath: /opt/youtrack/logs - name: opt-youtrack-backups mountPath: /opt/youtrack/backups volumes: - name: opt-youtrack-data persistentVolumeClaim: claimName: youtrack-data-pv-claim - name: opt-youtrack-conf persistentVolumeClaim: claimName: youtrack-conf-pv-claim - name: opt-youtrack-logs persistentVolumeClaim: claimName: youtrack-logs-pv-claim - name: opt-youtrack-backups persistentVolumeClaim: claimName: youtrack-backups-pv-claim Apply the Deployment:\nkubectl apply -f youtrack-deployment.yaml Make sure the PVCs are bound correctly by checking their status:\nkubectl get pvc -n youtrack You should see the status as Bound for all PVCs.\nvijay@controlplane:~$ k get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS VOLUMEATTRIBUTESCLASS REASON AGE pvc-35efef16-c771-4d39-88f4-6e5b15cc2ea2 1Gi RWO Delete Bound youtrack/youtrack-conf-pv-claim longhorn \u0026lt;unset\u0026gt; 60s pvc-64f43503-41f3-42cc-98d7-a5e0632b8753 5Gi RWO Delete Bound youtrack/youtrack-data-pv-claim longhorn \u0026lt;unset\u0026gt; 60s pvc-a1a5ae9d-402c-4913-a6d8-5f5282c6de73 2Gi RWO Delete Bound youtrack/youtrack-backups-pv-claim longhorn \u0026lt;unset\u0026gt; 60s pvc-ff4dd470-1c35-4f00-b6bc-11c1349b5b18 1Gi RWO Delete Bound youtrack/youtrack-logs-pv-claim longhorn \u0026lt;unset\u0026gt; 60s vijay@controlplane:~$ k get pvc -n youtrack NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS VOLUMEATTRIBUTESCLASS AGE youtrack-backups-pv-claim Bound pvc-a1a5ae9d-402c-4913-a6d8-5f5282c6de73 2Gi RWO longhorn \u0026lt;unset\u0026gt; 2m youtrack-conf-pv-claim Bound pvc-35efef16-c771-4d39-88f4-6e5b15cc2ea2 1Gi RWO longhorn \u0026lt;unset\u0026gt; 2m youtrack-data-pv-claim Bound pvc-64f43503-41f3-42cc-98d7-a5e0632b8753 5Gi RWO longhorn \u0026lt;unset\u0026gt; 2m youtrack-logs-pv-claim Bound pvc-ff4dd470-1c35-4f00-b6bc-11c1349b5b18 1Gi RWO longhorn \u0026lt;unset\u0026gt; 2m Step 4: Create a Service Create a Service to expose the YouTrack application within the cluster. Target the port 8080, which is the default port for YouTrack.\n# youtrack-service.yaml apiVersion: v1 kind: Service metadata: name: youtrack namespace: youtrack spec: ports: - name: \u0026#34;http\u0026#34; port: 80 protocol: TCP targetPort: 8080 selector: app: youtrack type: ClusterIP status: loadBalancer: {} Apply the Service:\nkubectl apply -f youtrack-service.yaml Step 5: Create an Ingress Resource Create an Ingress resource to expose YouTrack externally. This will allow you to access YouTrack via a domain name.\n# youtrack-ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: youtrack-ingress namespace: youtrack spec: ingressClassName: nginx rules: - host: track.yourdomain.com http: paths: - path: / pathType: Prefix backend: service: name: youtrack port: number: 80 Apply the Ingress resource:\nkubectl apply -f youtrack-ingress.yaml Step 6: Configure Cloudflare Tunnel To securely access your YouTrack instance, you can use Cloudflare Tunnel (Argo Tunnel). This allows you to expose your service without opening ports on your firewall. Also, you can skip Built-in TLS of YouTrack and use Cloudflare\u0026rsquo;s TLS for secure access.\nInstead of repeating the steps to set up Cloudflare Tunnel, I recommend you to follow my previous guide on Expose Kubernetes Applications Securely to the Internet with Cloudflare Tunnel and Nginx Ingress. Once you have set up the Cloudflare Tunnel, you can access your YouTrack instance at https://track.yourdomain.com\nStep 7: Access YouTrack and Use the Wizard Token Once everything is set up, open your web browser and navigate to https://track.yourdomain.com. You should see the loading screen of YouTrack, and then you will be prompted to enter the wizard token.\nStep 7.1: Obtain the Wizard Token Check the logs of the YouTrack pod to find the wizard token:\nExample: At the end of the logs, you will see a line similar to this:\nvijay@controlplane:~$ k logs youtrack-deployment-69fd966796-xb67v -f Starting YouTrack... * Configuring JetBrains YouTrack 2025.1 * Made default base-url \u0026#39;http://localhost:8080/\u0026#39; from hostname \u0026#39;localhost\u0026#39; and listen port \u0026#39;8080\u0026#39; * JetBrains YouTrack 2025.1 runtime environment is successfully configured * Loading logging configuration from /opt/youtrack/lib/ext/log4j.xml * Redirecting JetBrains YouTrack 2025.1 logging to /opt/youtrack/logs/internal/services/bundleProcess * Configuring Service-Container[bundleProcess] * Configuring Bundle Backend Service * Configuring Configuration Wizard * Starting Service-Container[bundleProcess] * Starting Bundle Backend Service * Starting Configuration Wizard * JetBrains YouTrack 2025.1 Configuration Wizard will listen inside container on {0.0.0.0:8080}/ after start and can be accessed by URL [http://\u0026lt;put-your-docker-HOST-name-here\u0026gt;:\u0026lt;put-host-port-mapped-to-container-port-8080-here\u0026gt;//?wizard_token=ABCDEFGHIJKLMNOPQRSTUVWX] Step 7.2: Use the Wizard Token Copy the wizard token from the logs and paste it into the YouTrack setup wizard page. This token is used to configure the initial settings of YouTrack.\nStep 8: Complete the Setup Wizard Once you have entered the wizard token, you click on Setup button to proceed with the setup wizard.\nSince you already setup the Cloudflare Tunnel, you can skip the Https configuration in the setup wizard and proceed with the HTTP configuration.\nAs you see in the image above, you can skip the HTTPS configuration and proceed with HTTP configuration.\nMake sure to change the Base URL to your domain name, e.g., https://track.yourdomain.com.\nKeep the Application Port as 8080 and Application Listen Address as 0.0.0.0 in advanced settings.\nIn my case, I got an error while setting up the YouTrack instance because I had to restart my deployment after creating the PVCs. So youTrack complained that the Data directory is not empty. If you encounter this error, you can do the following:\nExec into the YouTrack pod and then, remove the contents of the /opt/youtrack/data directory:\nkubectl exec -it -n youtrack \u0026lt;your-pod-name\u0026gt; -- bash rm -rf /opt/youtrack/data/* After clearing the data directory, you can restart the YouTrack deployment:\nkubectl rollout restart deployment youtrack-deployment -n youtrack Repeat the setup wizard steps again, and this time it should work without any issues.\nStep 9: Use Default License In the next screen, you will be prompted to enter a license key. Since you are self-hosting YouTrack for personal use or for a small team, you can use the default license key provided by JetBrains.\nNext to that, add your administrator account by entering your username and password. This account will have full administrative privileges in YouTrack.\nStep 10: Access YouTrack Once the setup is complete, you can access your YouTrack instance at https://track.yourdomain.com.\nConclusion Congratulations! You have successfully self-hosted JetBrains YouTrack in a Kubernetes environment.\nReference Resources JetBrains YouTrack Official Site YouTrack Hangs on Start - Support Article Deploy YouTrack in Kubernetes - Documentation YouTrack Pricing and Buy Page ","permalink":"http://localhost:1313/posts/self-hosting/how-to-self-host-jetbrains-youtrack-project-management-tool-in-kubernetes/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eIn this guide, I will walk through the process of self-hosting JetBrains YouTrack, a powerful project management tool, in a Kubernetes environment. YouTrack is designed to help teams manage their projects efficiently with features like issue tracking, agile boards, and customizable workflows.\nIt is also free for up to 10 users, making it an excellent choice for small teams or personal projects.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"youtrack-homepage.png\" loading=\"lazy\" src=\"/images/youtrack-homepage.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"prerequisites\"\u003ePrerequisites\u003c/h1\u003e\n\u003cp\u003eBefore we begin, ensure you have the following prerequisites:\u003c/p\u003e","title":"How To Self-Host JetBrains YouTrack Project Management Tool In Kubernetes"},{"content":"Introduction This guide will help you identify if your public IP address has any open ports or services that could be unintentionally exposed to the internet. This is crucial for maintaining the security of your network and devices.\nBased on RFC1918, private IP addresses are not routable on the public internet.\nWhat is RFC1918?\nRFC1918 is a standard that defines private IP address ranges that are reserved for use within private networks. RFC1918 designates the following three ranges for private networks: 10.0.0.0 - 10.255.255.255: (10.0.0.0/8) 172.16.0.0 - 172.31.255.255: (172.16.0.0/12) 192.168.0.0 - 192.168.255.255: (192.168.0.0/16) Steps You can use online tools to scan your public IP address for open ports and services. Use a port scan tool like Censys to search for a public IP address.\nStep 1: Find Your Public IP Address To check if, any devices or services (e.g. Proxmox, SSH, or web servers) are unintentionally exposed to the internet.\nFind your public IP address:\n- macOS/Linux: ```bash curl ifconfig.me ``` - Windows (PowerShell): ```powershell curl ifconfig.me ``` Lets say your public IP is 88.90.123.456. Copy this IP address and proceed to the next step.\nStep 2: Use Censys to Search for Open Ports Go to https://search.censys.io\nPaste the public IP into the search bar and view any open ports or services listed.\nFor example:\nConclusion ✅ If no results show up, your network is likely not exposing anything publicly.\n❌ If results show up, review the services and ports listed to ensure they are intended to be public.\n","permalink":"http://localhost:1313/posts/security/check-public-ip-open-ports/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eThis guide will help you identify if your public IP address has any open ports or services that could be unintentionally exposed to the internet.\nThis is crucial for maintaining the security of your network and devices.\u003c/p\u003e\n\u003cp\u003eBased on RFC1918, private IP addresses are not routable on the public internet.\u003c/p\u003e\n\u003cp\u003eWhat is RFC1918?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRFC1918 is a standard that defines private IP address ranges that are reserved for use within private networks.\u003c/li\u003e\n\u003cli\u003eRFC1918 designates the following three ranges for private networks:\n\u003cul\u003e\n\u003cli\u003e10.0.0.0 - 10.255.255.255: (10.0.0.0/8)\u003c/li\u003e\n\u003cli\u003e172.16.0.0 - 172.31.255.255: (172.16.0.0/12)\u003c/li\u003e\n\u003cli\u003e192.168.0.0 - 192.168.255.255: (192.168.0.0/16)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"steps\"\u003eSteps\u003c/h1\u003e\n\u003cp\u003eYou can use online tools to scan your public IP address for open ports and services.\nUse a port scan tool like \u003cstrong\u003eCensys\u003c/strong\u003e to search for a public IP address.\u003c/p\u003e","title":"Check Your Public IP for Exposed Open Ports"},{"content":"Introduction In this guide, we will learn how to expose a Kubernetes application securely to the internet using Cloudflare Tunnel and Nginx Ingress. This setup allows you to leverage Cloudflare\u0026rsquo;s security features while managing your application traffic efficiently.\nWe are going to use:\nCloudflare Tunnel to expose our application securely to the internet. Kubernetes Nginx Ingress to route traffic to our application. Prerequisites A Cloudflare account with the domain added. A Kubernetes cluster set up with Nginx Ingress Controller installed. Root or sudo access to the Kubernetes cluster. Deployment Guide Step 1: Install Cloudflare Tunnel sudo mkdir -p --mode=0755 /usr/share/keyrings curl -fsSL https://pkg.cloudflare.com/cloudflare-main.gpg | sudo tee /usr/share/keyrings/cloudflare-main.gpg \u0026gt;/dev/null echo \u0026#34;deb [signed-by=/usr/share/keyrings/cloudflare-main.gpg] https://pkg.cloudflare.com/cloudflared any main\u0026#34; | sudo tee /etc/apt/sources.list.d/cloudflared.list sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install cloudflared Step 2: Authenticate Cloudflare Tunnel sudo cloudflared tunnel login Don\u0026rsquo;t worry, if you see a login url in the server terminal, just copy it and paste it in your personal browser. After logging in, you will see a success message in the server terminal.\nStep 3: Create a Tunnel sudo cloudflared tunnel create \u0026lt;tunnel-name\u0026gt; Example:\nsudo cloudflared tunnel create nginx-tunnel Once the tunnel is created, you will see a message with the tunnel ID and a certificate file path.\nExample output:\nvijay@controlplane:~$ cloudflared tunnel create nginx-tunnel Tunnel credentials written to /root/.cloudflared/lmnop-0ce8-efgh-8c67-abcd.json. cloudflared chose this file based on where your origin certificate was found. Keep this file secret. To revoke these credentials, delete the tunnel. Created tunnel nginx-tunnel with id lmnop-0ce8-efgh-8c67-abcd You can check the list of tunnels created by running:\nsudo cloudflared tunnel list sudo cloudflared tunnel info nginx-tunnel Copy the tunnel ID and certificate file path for later use. I would recommend renaming the certificate file to something more meaningful, like nginx-tunnel-credential.json.\nsudo mkdir /home/vijay/.cloudflared \u0026amp;\u0026amp; sudo chown vijay:vijay /home/vijay/.cloudflared \u0026amp;\u0026amp; sudo chmod 700 /home/vijay/.cloudflared \u0026amp;\u0026amp; sudo chmod 600 /home/vijay/.cloudflared/* sudo cp /root/.cloudflared/lmnop-0ce8-efgh-8c67-abcd.json /home/vijay/.cloudflared/nginx-tunnel-credential.json Step 4: Create a Kubernetes Secret for Cloudflare Tunnel Credentials I am creating a secret in the cloudflare namespace, but you can create it in any namespace you prefer. Make sure to update the ConfigMap and Deployment accordingly. Feel free to change the path to the credential file if you have it in a different location.\nkubectl create namespace cloudflare kubectl -n cloudflare create secret generic cloudflared-creds \\ --from-file=nginx-tunnel-credential.json=/home/vijay/.cloudflared/nginx-tunnel-credential.json The next step is to create a ConfigMap with the Cloudflare Tunnel configuration.\nStep 5: Create a Kubernetes ConfigMap for Cloudflare Tunnel # cloudflared-config.yaml apiVersion: v1 kind: ConfigMap metadata: name: cloudflared-config namespace: cloudflare data: config.yaml: | tunnel: nginx-tunnel credentials-file: /etc/cloudflared/creds/nginx-tunnel-credential.json ingress: - hostname: \u0026#39;*.yourdomain.com\u0026#39; originRequest: noTLSVerify: true service: https://ingress-nginx-controller.ingress-nginx.svc.cluster.local:443 - service: http_status:404 Explanation:\ntunnel: The name of the tunnel you created. credentials-file: Don\u0026rsquo;t be confused with the path to the credential file, this is the path inside the container where the credential file will be mounted. ingress: This section defines the routing rules for the tunnel. hostname: The domain or subdomain you want to expose. Replace yourdomain.com with your actual domain. originRequest.noTLSVerify: Set to true to skip TLS verification for the service. service: The service URL that the tunnel will route traffic to. In this case, it routes to the Nginx Ingress Controller service which is typically named ingress-nginx-controller in the ingress-nginx namespace. Adjust the service name and namespace as per your setup. http_status:404: This is a catch-all rule that returns a 404 status for any unmatched requests. Step 6: Create Deployment for Cloudflare Tunnel # cloudflared-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: cloudflared namespace: cloudflare spec: replicas: 1 selector: matchLabels: app: cloudflared template: metadata: labels: app: cloudflared spec: containers: - name: cloudflared image: cloudflare/cloudflared:2025.6.1 args: [\u0026#34;tunnel\u0026#34;, \u0026#34;--config\u0026#34;, \u0026#34;/etc/cloudflared/config.yaml\u0026#34;, \u0026#34;run\u0026#34;] volumeMounts: - name: config mountPath: /etc/cloudflared/config.yaml subPath: config.yaml - name: creds mountPath: /etc/cloudflared/creds volumes: - name: config configMap: name: cloudflared-config - name: creds secret: secretName: cloudflared-creds Explanation:\nargs: The command to run the Cloudflare Tunnel with the specified configuration file. volumeMounts: Mounts the ConfigMap and secret containing the Cloudflare Tunnel configuration and credentials. This is the path above ConfigMap uses /etc/cloudflared/creds/nginx-tunnel-credential.json. Step 7: Apply the ConfigMap and Deployment kubectl apply -f cloudflared-config.yaml kubectl apply -f cloudflared-deployment.yaml Make sure your Secret, ConfigMap, and Deployment are in the same namespace or adjust the commands accordingly. Otherwise, your Deployment won\u0026rsquo;t be able to access the ConfigMap and Secret.\nStep 8: CNAME Configuration in Cloudflare Go to your Cloudflare dashboard and navigate to the DNS settings for your domain. Create a CNAME record for the subdomain you want to expose, pointing it to *.yourdomain.com.\nIn the Target field, enter the tunnel-id.cfargotunnel.com Example: lmnop-0ce8-efgh-8c67-abcd.cfargotunnel.com\nWithout this step, the Cloudflare Tunnel won\u0026rsquo;t be able to route traffic to your application.\nStep 9: Expose Nginx Deployment using Ingress kubectl create namespace nginx kubectl -n nginx create deployment nginx --image=nginx:alpine kubectl -n nginx expose deployment nginx --port 80 Step 10: Create an Ingress Resource kubectl -n nginx create ingress nginx-ingress \\ --rule=\u0026#34;nginx.yourdomain.com/*=nginx:80\u0026#34; Step 11: Verify the Ingress Resource kubectl -n nginx get ingress nginx-ingress You should see the Ingress resource with the hostname and backend service.\nWhola! Your application is now exposed securely to the internet.\nConclusion In this guide, we have successfully exposed a Kubernetes application securely to the internet using Cloudflare Tunnel and Nginx Ingress. This setup allows you to leverage Cloudflare\u0026rsquo;s security features while managing your application traffic efficiently.\n","permalink":"http://localhost:1313/posts/kubernetes/expose-k8s-apps-to-internet-using-cloudflare-tunnel/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eIn this guide, we will learn how to expose a Kubernetes application securely to the internet using Cloudflare Tunnel and Nginx Ingress. This setup allows you to leverage Cloudflare\u0026rsquo;s security features while managing your application traffic efficiently.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"intro-expose-k8s-apps-to-internet.png\" loading=\"lazy\" src=\"/images/intro-expose-k8s-apps-to-internet.png\"\u003e\u003c/p\u003e\n\u003cp\u003eWe are going to use:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCloudflare Tunnel to expose our application securely to the internet.\u003c/li\u003e\n\u003cli\u003eKubernetes Nginx Ingress to route traffic to our application.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"prerequisites\"\u003ePrerequisites\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eA Cloudflare account with the domain added.\u003c/li\u003e\n\u003cli\u003eA Kubernetes cluster set up with Nginx Ingress Controller installed.\u003c/li\u003e\n\u003cli\u003eRoot or sudo access to the Kubernetes cluster.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"deployment-guide\"\u003eDeployment Guide\u003c/h1\u003e\n\u003ch3 id=\"step-1-install-cloudflare-tunnel\"\u003eStep 1: Install Cloudflare Tunnel\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo mkdir -p --mode\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"m\"\u003e0755\u003c/span\u003e /usr/share/keyrings\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecurl -fsSL https://pkg.cloudflare.com/cloudflare-main.gpg \u003cspan class=\"p\"\u003e|\u003c/span\u003e sudo tee /usr/share/keyrings/cloudflare-main.gpg \u0026gt;/dev/null\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eecho\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;deb [signed-by=/usr/share/keyrings/cloudflare-main.gpg] https://pkg.cloudflare.com/cloudflared any main\u0026#34;\u003c/span\u003e \u003cspan class=\"p\"\u003e|\u003c/span\u003e sudo tee /etc/apt/sources.list.d/cloudflared.list\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo apt-get update \u003cspan class=\"o\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e sudo apt-get install cloudflared\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch3 id=\"step-2-authenticate-cloudflare-tunnel\"\u003eStep 2: Authenticate Cloudflare Tunnel\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo cloudflared tunnel login\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eDon\u0026rsquo;t worry, if you see a login url in the server terminal, just copy it and paste it in your personal browser.\nAfter logging in, you will see a success message in the server terminal.\u003c/p\u003e","title":"Expose Kubernetes Applications Securely to the Internet with Cloudflare Tunnel and Nginx Ingress"},{"content":"Introduction Metrics Server is a cluster-wide aggregator of resource usage data in Kubernetes. It collects metrics from the kubelet on each node and provides them to the Kubernetes API server, which can be used for horizontal pod autoscaling and other purposes.\nPrerequisites A running Kubernetes cluster (version 1.8 or later). kubectl command-line tool installed and configured to communicate with your cluster. Installation Steps kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml Verification To verify that Metrics Server is running correctly, you can check the status of the Metrics Server pod:\nkubectl get pods -n kube-system You should see a pod named metrics-server-\u0026lt;hash\u0026gt; in the Running state.\nYou can also check if Metrics Server is collecting metrics by running:\nkubectl top nodes Example output:\nvijay@controlplane:~$ kubectl top nodes NAME CPU(cores) CPU(%) MEMORY(bytes) MEMORY(%) controlplane 89m 1% 2672Mi 22% node01 41m 2% 1718Mi 44% node02 59m 2% 2460Mi 31% To check metrics for pods in all namespaces, you can run:\nkubectl top pods --all-namespaces To check metrics for a specific namespace, you can run:\nkubectl top pods -n \u0026lt;namespace\u0026gt; ","permalink":"http://localhost:1313/posts/kubernetes/install-metrics-server-kubernetes/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eMetrics Server is a cluster-wide aggregator of resource usage data in Kubernetes.\nIt collects metrics from the kubelet on each node and provides them to the Kubernetes API server, which can be used for horizontal pod autoscaling and other purposes.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"how-metrics-server-works.png\" loading=\"lazy\" src=\"/images/how-metrics-server-works.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"prerequisites\"\u003ePrerequisites\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eA running Kubernetes cluster (version 1.8 or later).\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekubectl\u003c/code\u003e command-line tool installed and configured to communicate with your cluster.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"installation-steps\"\u003eInstallation Steps\u003c/h1\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch1 id=\"verification\"\u003eVerification\u003c/h1\u003e\n\u003cp\u003eTo verify that Metrics Server is running correctly, you can check the status of the Metrics Server pod:\u003c/p\u003e","title":"How to install Metrics Server on Kubernetes"},{"content":"\nIntroduction This guide will walk you through the following steps to set up a 3-node Kubernetes cluster using kubeadm:\nConfigure unique hostnames for each node. Set up networking and update the /etc/hosts file. Install required system packages and disable swap. Install and configure the container runtime (containerd) and enable IP forwarding. Install Kubernetes components: kubeadm, kubelet, and kubectl. Initialize the control plane node with kubeadm. Set up pod networking using Calico CNI. Join worker nodes to the cluster. Verify the cluster status and apply additional configurations. Prerequisites Create three VMs or physical servers with Ubuntu 22.04 LTS or later. Make sure all nodes can communicate with each other over the network and has internet access. Setup Step 1: Setup Hostnames on all nodes On each node, set a unique hostname using the following command:\nsudo hostnamectl set-hostname \u0026lt;your-node-hostname\u0026gt; For example, you can use the following hostnames:\n# on control plane node sudo hostnamectl set-hostname controlplane # on worker1 node sudo hostnamectl set-hostname worker-node01 # on worker2 node sudo hostnamectl set-hostname worker-node02 Step 2: Configure Node IP address details in all nodes Edit the /etc/hosts file on all nodes to include the IP addresses and hostnames of all nodes in the cluster.\nsudo nano /etc/hosts Add the following lines to the file:\nMake sure to replace the IP addresses with your actual node IPs. In my case, IPs of the nodes are:\n# /etc/hosts 10.10.10.50 controlplane 10.10.10.51 worker-node01 10.10.10.52 worker-node02 Step 3: Update and Install Required Packages on all nodes sudo apt update \u0026amp;\u0026amp; sudo apt install -y apt-transport-https ca-certificates curl gpg lsb-release gnupg software-properties-common sudo swapoff -a sudo sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/\u0026#39; /etc/fstab Package Purpose apt-transport-https Enables apt to use HTTPS for downloading packages. ca-certificates Provides trusted SSL certificates for secure connections. curl Tool for transferring data from URLs, often used to download files. gpg and gnupg Tools for managing GPG keys, used to verify package authenticity. lsb-release Provides Linux Standard Base information about the system. software-properties-common Adds scripts for managing apt repositories. Command Purpose sudo swapoff -a Ensures that swap is disabled, which is a requirement for Kubernetes to function properly. sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/' /etc/fstab Comments out any swap entries in the /etc/fstab file to prevent swap from being enabled on reboot. Step 4: Install Containerd and Enable IP Forwarding Before installing Kubernetes components, we need to set up the container runtime and enable IP forwarding. IP forwarding is required for Kubernetes to allow communication between pods across nodes.\nMake sure to run the following steps on all nodes (control plane and worker nodes).\nStep 4.1: Enable IP Forwarding on all nodes sudo sysctl -w net.ipv4.ip_forward=1 Then make it persistent across reboots by editing the sysctl configuration:\necho \u0026#34;net.ipv4.ip_forward = 1\u0026#34; | sudo tee /etc/sysctl.d/99-kubernetes.conf sudo sysctl --system Step 4.2: Install Containerd on all nodes sudo apt install -y containerd # Create default config file sudo mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml # Change cgroupDriver to systemd sudo sed -i \u0026#39;s/SystemdCgroup = false/SystemdCgroup = true/\u0026#39; /etc/containerd/config.toml # Restart containerd sudo systemctl restart containerd sudo systemctl enable containerd Step 5: Install kubeadm, kubelet, kubectl on all nodes Note: I am using Kubernetes version v1.32.0 in this guide. You can change it to the latest stable version if needed.\nsudo mkdir -p /etc/apt/keyrings curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list sudo apt update sudo apt install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl Step 6: Initialize the ControlPlane Node (Only on controlplane node) Step 6.1: Initialize the kubeadm on control plane Run below command only on the controlplane node. Not on worker nodes.\nIf you want to use different CIDR for pod or service, you can change the --pod-network-cidr and --service-cidr options accordingly.\nKept 192.168.0.0/16 for pod network CIDR as it is the default config for Calico CNI. If you plan to change it, make sure to update the Calico manifest later.\nsudo kubeadm init \\ --apiserver-advertise-address=10.10.10.50 \\ --pod-network-cidr=192.168.0.0/16 \\ --service-cidr=10.100.0.0/16 \\ --kubernetes-version=v1.32.0 Step 6.2: Set up kubeconfig for the controlplane node mkdir -p $HOME/.kube sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Step 7: Install Calico CNI for Pod Networking (Only on controlplane node) Since our CIDR for pod and service are below:\n--pod-network-cidr=192.168.0.0/16: for Calico or your CNI\n--service-cidr=10.100.0.0/16: for Kubernetes services (ClusterIP, etc.)\nMake sure these do not overlap with your existing network ranges.\nWhen using a non-default pod CIDR, you must modify the Calico manifest accordingly.\nStep 7.1: Download and Apply Calico Manifest curl -O https://raw.githubusercontent.com/projectcalico/calico/v3.27.2/manifests/calico.yaml Step 7.2: Edit Calico Manifest sudo nano calico.yaml Search for the following block:\n- name: CALICO_IPV4POOL_CIDR value: \u0026#34;192.168.0.0/16\u0026#34; Make sure it matches your --pod-network-cidr you used during kubeadm init.\nStep 7.3: Apply the Calico Manifest kubectl apply -f calico.yaml -n kube-system Wait for the Calico pods to be up and running.\nkubectl get pods -n kube-system Example output:\nvijay@controlplane:~$ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-7967497bcf-j2tj2 1/1 Running 0 60s calico-node-8sqtx 1/1 Running 0 40s calico-node-mgjbt 1/1 Running 0 41s calico-node-qkdsz 1/1 Running 0 43s Now your control plane node is ready with Calico CNI installed and ready for worker nodes to join.\nStep 8: Join Worker Nodes to the Cluster From kubeadm init, you’ll get a kubeadm join command. Run it on both worker-node01 and worker-node02.\nExample:\nsudo kubeadm join 10.10.10.50:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:\u0026lt;hash\u0026gt; If you lost the token, re-generate it using the following command on the controlplane node:\nsudo kubeadm token create --print-join-command Step 9: Verify Cluster Status and add additional configurations After joining the worker nodes, you can verify the cluster status from the controlplane node.\nkubectl get nodes You should see:\ncontrolplane Ready control-plane worker-node01 Ready \u0026lt;none\u0026gt; worker-node02 Ready \u0026lt;none\u0026gt; Step 9.1: Set up kubeconfig for root user On the control plane node, only if you want to use kubectl from your controlplane node as root user.\nsudo cp /etc/kubernetes/admin.conf /root/.kube/config sudo chown root:root /root/.kube/config Step 9.2: Enable Bash Completion for kubectl sudo apt install -y bash-completion echo \u0026#34;source \u0026lt;(kubectl completion bash)\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;alias k=kubectl\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;complete -F __start_kubectl k\u0026#34; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc Conclusion You have successfully set up a 3-node Kubernetes cluster using kubeadm. The control plane node is running with Calico CNI for pod networking, and the worker nodes are joined to the cluster. You can now deploy applications and manage your Kubernetes cluster effectively.\n","permalink":"http://localhost:1313/posts/kubernetes/kubeadm-kubernetes-3-node-cluster-setup-guide/","summary":"\u003cp\u003e\u003cimg alt=\"kubeadm-3node-cluster-setup.png\" loading=\"lazy\" src=\"/images/kubeadm-3node-cluster-setup.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThis guide will walk you through the following steps to set up a 3-node Kubernetes cluster using kubeadm:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConfigure unique hostnames for each node.\u003c/li\u003e\n\u003cli\u003eSet up networking and update the \u003ccode\u003e/etc/hosts\u003c/code\u003e file.\u003c/li\u003e\n\u003cli\u003eInstall required system packages and disable swap.\u003c/li\u003e\n\u003cli\u003eInstall and configure the container runtime (\u003ccode\u003econtainerd\u003c/code\u003e) and enable IP forwarding.\u003c/li\u003e\n\u003cli\u003eInstall Kubernetes components: \u003ccode\u003ekubeadm\u003c/code\u003e, \u003ccode\u003ekubelet\u003c/code\u003e, and \u003ccode\u003ekubectl\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eInitialize the control plane node with \u003ccode\u003ekubeadm\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eSet up pod networking using Calico CNI.\u003c/li\u003e\n\u003cli\u003eJoin worker nodes to the cluster.\u003c/li\u003e\n\u003cli\u003eVerify the cluster status and apply additional configurations.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCreate three VMs or physical servers with Ubuntu 22.04 LTS or later.\u003c/li\u003e\n\u003cli\u003eMake sure all nodes can communicate with each other over the network and has internet access.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"setup\"\u003eSetup\u003c/h2\u003e\n\u003ch3 id=\"step-1-setup-hostnames-on-all-nodes\"\u003eStep 1: Setup Hostnames on all nodes\u003c/h3\u003e\n\u003cp\u003eOn each node, set a unique hostname using the following command:\u003c/p\u003e","title":"How to Set Up a 3-Node Kubernetes Cluster with Kubeadm"},{"content":"How to Enable Auto Login on Proxmox Console (TTY) What is tty? tty stands for \u0026ldquo;teletypewriter\u0026rdquo; and refers to a terminal interface in Unix-like operating systems. It allows users to interact with the system through a command-line interface.\nWhat is getty? getty is a program that manages physical or virtual terminals on Unix-like systems. It is responsible for prompting for a login name and starting the login process.\nIf you want to enable auto-login on the Proxmox console (TTY), you can do this by modifying the getty service configuration. This allows you to log in automatically without entering a username and password each time you access the console. This is helpful when your homelab server restarts for some reason, and you want to avoid manual login.\nStep 1: Edit the getty service configuration sudo mkdir -p /etc/systemd/system/getty@tty1.service.d/ Create an override config:\nsudo nano /etc/systemd/system/getty@tty1.service.d/override.conf Add this content:\n[Service] ExecStart= ExecStart=-/sbin/agetty --autologin root --noclear %I $TERM The line ExecStart= clears the default start command.\nThe next line sets a new start command:\nExecStart=-/sbin/agetty --autologin root --noclear %I $TERM This tells agetty to automatically log in as root on TTY1 without prompting for credentials.\nIf you want to auto-login as a different user, replace root with your desired username.\nStep 2: Reload systemd and restart getty sudo systemctl daemon-reload sudo systemctl restart getty@tty1 Step 3: Test it Switch to tty1 by pressing Ctrl + Alt + F1 or reboot to test fresh login It should log in automatically as root or your user Conclusion Now you have successfully enabled auto-login on the Proxmox console (TTY). This setup is particularly useful for homelab environments where you want quick access without manual login steps after reboots or power failures.\nBut be cautious with security, as auto-login can expose your system to unauthorized access if someone has physical access to the server.\nAlso note when you access the Proxmox web interface, you will still need to log in with your credentials.\n","permalink":"http://localhost:1313/posts/proxmox/proxmox-enable-auto-login-console/","summary":"\u003ch1 id=\"how-to-enable-auto-login-on-proxmox-console-tty\"\u003eHow to Enable Auto Login on Proxmox Console (TTY)\u003c/h1\u003e\n\u003ch4 id=\"what-is-tty\"\u003eWhat is tty?\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003etty\u003c/code\u003e stands for \u0026ldquo;teletypewriter\u0026rdquo; and refers to a terminal interface in Unix-like operating systems. It allows users to interact with the system through a command-line interface.\u003c/p\u003e\n\u003ch4 id=\"what-is-getty\"\u003eWhat is \u003ccode\u003egetty\u003c/code\u003e?\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003egetty\u003c/code\u003e is a program that manages physical or virtual terminals on Unix-like systems. It is responsible for prompting for a login name and starting the login process.\u003c/p\u003e\n\u003cp\u003eIf you want to enable auto-login on the Proxmox console (TTY), you can do this by modifying the \u003ccode\u003egetty\u003c/code\u003e service configuration. This allows you to log in automatically without entering a username and password each time you access the console.\nThis is helpful when your homelab server restarts for some reason, and you want to avoid manual login.\u003c/p\u003e","title":"How to Enable Auto Login on Proxmox Console"},{"content":"Introduction If you don’t have a paid Proxmox subscription, you’ll see a warning about the Enterprise repository. This is normal for home labs, but you can easily switch to the free no-subscription repository and get rid of the alert.\nSteps to Fix the Warning Step 1: Open the Proxmox APT sources file nano /etc/apt/sources.list.d/pve-enterprise.list Step 2: Disable the enterprise repository Add a # at the start of the line so it looks like this:\n# deb https://enterprise.proxmox.com/debian/pve bookworm pve-enterprise Step 3: Add the no-subscription repository Open your main sources list:\nnano /etc/apt/sources.list Add this line if it’s not already there:\ndeb http://download.proxmox.com/debian/pve bookworm pve-no-subscription Step 4: If you use Ceph, disable the enterprise Ceph repo (Optional) Edit the Ceph sources file:\nnano /etc/apt/sources.list.d/ceph.list Comment out the enterprise line and add the no-subscription one:\n# deb https://enterprise.proxmox.com/debian/ceph-quincy bookworm enterprise deb http://download.proxmox.com/debian/ceph-quincy bookworm no-subscription Step 5: Update your package lists apt-get update That’s it! The warning should be gone, and you’ll still get updates from the free repository.\nConclusion Now you can use Proxmox without the subscription warning. This is perfect for home labs or testing environments where you don’t need a paid subscription. Enjoy your Proxmox experience without the distraction of the subscription alert!\n","permalink":"http://localhost:1313/posts/proxmox/proxmox-remove-subscription-warning/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Proxmox Subscription Warning Image\" loading=\"lazy\" src=\"/images/proxmox-ve-enterprise-subscription-alert-box-screenshot.jpeg\"\u003e\u003c/p\u003e\n\u003cp\u003eIf you don’t have a paid Proxmox subscription, you’ll see a warning about the Enterprise repository. This is normal for home labs, but you can easily switch to the free no-subscription repository and get rid of the alert.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"steps-to-fix-the-warning\"\u003eSteps to Fix the Warning\u003c/h2\u003e\n\u003ch3 id=\"step-1-open-the-proxmox-apt-sources-file\"\u003eStep 1: Open the Proxmox APT sources file\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003enano /etc/apt/sources.list.d/pve-enterprise.list\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003ch3 id=\"step-2-disable-the-enterprise-repository\"\u003eStep 2: Disable the enterprise repository\u003c/h3\u003e\n\u003cp\u003eAdd a \u003ccode\u003e#\u003c/code\u003e at the start of the line so it looks like this:\u003c/p\u003e","title":"How to Remove Proxmox Subscription Warning"},{"content":"Introduction This guide shows you how to set up a secure and flexible Proxmox VE homelab. You will:\nIsolate your VM network but keep internet access. Securely access the Proxmox web UI using Cloudflare Tunnel and custom DNS. Block direct IP access to the Proxmox UI. Prepare for adding more services in the future. Prerequisite Before you start, ensure you have:\nAlready installed Proxmox VE on your machine. A basic understanding of Linux command line. A Cloudflare account with a domain set up (e.g., yourdomain.com). Already created a linux bridge network in Proxmox for your VMs. Check out my blog post on How to Configure DHCP Server to Create vmbr Bridge Network for guidance. Example values we are going to use Assuming you have a Proxmox VE installation with the following network configuration: Note that these values are examples. You should replace them with your actual network settings.\nSetting Example Value Description LAN IP 10.20.30.40/24 Proxmox server IP address Gateway/DNS 10.20.30.1 Default gateway and DNS Hostname homelab.yourdomain.com Proxmox hostname Domain yourdomain.com Cloudflare-managed domain Steps to Secure and Isolate Proxmox VE Homelab Step 1: Initial Proxmox VE Setup apt-get update apt-get upgrade Step 1.1: Open /etc/hostname and set the following entry: You can use any hostname you prefer, but for this guide, we will use: homelab\nhomelab Step 1.2: Open and check values for /etc/hosts: 127.0.0.1 localhost.localdomain localhost 10.20.30.40 homelab.yourdomain.com homelab Step 2: Isolate your VM network but keep internet access To create an isolated linux bridge network, check out my blog How to Configure DHCP Server to Create vmbr Bridge Network.\nIf you want your Proxmox and its VMs on an isolated internal virtual network, but still able to access the internet. Follow these steps:\nStep 2.1: Network Plan Use Proxmox’s Linux bridges for VM/Container networks.\nvmbr0: Connected to physical NIC (eno1) — your main interface (10.20.30.40) vmbr1: Internal-only isolated virtual bridge (no physical NIC attached) Configure NAT for vmbr1 to allow internet for VMs while keeping them isolated Step 2.2: Create NAT Bridge (Isolated VM Network) Edit /etc/network/interfaces:\nauto lo iface lo inet loopback iface enp3s0 inet manual auto vmbr0 iface vmbr0 inet static address 10.20.30.40/24 gateway 10.20.30.1 bridge-ports enp3s0 bridge-stp off bridge-fd 0 dns-nameservers 10.20.30.1 auto vmbr1 iface vmbr1 inet static address 10.10.10.1/24 bridge-ports none bridge-stp off bridge-fd 0 post-up echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward post-up iptables -t nat -A POSTROUTING -s \u0026#39;10.10.10.0/24\u0026#39; -o vmbr0 -j MASQUERADE post-down iptables -t nat -D POSTROUTING -s \u0026#39;10.10.10.0/24\u0026#39; -o vmbr0 -j MASQUERADE iface enp2s0 inet manual iface wlp4s0 inet manual source /etc/network/interfaces.d/* Then run to apply the changes\nifreload -a Now, your VMs on vmbr1 can access the internet but are not exposed to your LAN.\nStep 3: Secure Remote Access via Cloudflare Tunnel To expose the Proxmox UI (8006) securely via your domain, use Cloudflare Tunnel (cloudflared). No port forwarding is needed.\nStep 3.1: Install cloudflared on Proxmox wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb sudo dpkg -i cloudflared-linux-amd64.deb Step 3.2: Authenticate with Cloudflare cloudflared tunnel login Follow the browser instructions. Select your domain: yourdomain.com.\nStep 3.3: Create the Tunnel cloudflared tunnel create proxmox-tunnel This gives a tunnel UUID like a1b2c3d4...\nStep 3.4: Configure the Tunnel Create /etc/cloudflared/config.yml:\ntunnel: a1b2c3d4... # from previous step credentials-file: /root/.cloudflared/875fc262-b752-46cf-958d-86f35815deed.json # from previous step ingress: - hostname: homelab.yourdomain.com service: https://localhost:8006 originRequest: noTLSVerify: true - service: http_status:404 Step 3.5: Route DNS in Cloudflare Run below command. This will create a DNS record in Cloudflare for your tunnel.\ncloudflared tunnel route dns proxmox-tunnel homelab.yourdomain.com Step 3.6: Run the Tunnel as a Service cloudflared service install systemctl enable --now cloudflared Now, only users with access to homelab.yourdomain.com via Cloudflare can access your Proxmox UI.\nStep 4: Block IP Access to https://\u0026lt;your-proxmox-ip\u0026gt;:8006 We’ll achieve this using Proxmox firewall rules using iptables.\nUse iptables (if you don’t want to use Proxmox firewall)\nStep 4.1: Block direct access to Proxmox UI iptables -A INPUT -p tcp --dport 8006 ! -s 127.0.0.1 -j DROP Step 4.2: Save the iptables rules by running below command apt install iptables-persistent iptables-save \u0026gt; /etc/iptables/rules.v4 Step 5: Verify It Works Now try:\nhttps://\u0026lt;your-public-LAN-IP\u0026gt;:8006 → Should fail (connection refused or timeout) https://homelab.yourdomain.com → Should work perfectly Conclusion Objective Implementation Details Isolated network with internet Created vmbr1, apply NAT masquerading via vmbr0 Secure remote Proxmox access Used Cloudflare Tunnel and custom DNS (homelab.yourdomain.com) Block access via IP/Port web UI to 127.0.0.1:8006 blocked ","permalink":"http://localhost:1313/posts/proxmox/secure-proxmox-with-cloudflare-tunnel/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThis guide shows you how to set up a secure and flexible Proxmox VE homelab. You will:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIsolate your VM network but keep internet access.\u003c/li\u003e\n\u003cli\u003eSecurely access the Proxmox web UI using Cloudflare Tunnel and custom DNS.\u003c/li\u003e\n\u003cli\u003eBlock direct IP access to the Proxmox UI.\u003c/li\u003e\n\u003cli\u003ePrepare for adding more services in the future.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"proxmox-ve-setup-title-image.png\" loading=\"lazy\" src=\"/images/proxmox-ve-setup-title-image.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"prerequisite\"\u003ePrerequisite\u003c/h2\u003e\n\u003cp\u003eBefore you start, ensure you have:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAlready installed Proxmox VE on your machine.\u003c/li\u003e\n\u003cli\u003eA basic understanding of Linux command line.\u003c/li\u003e\n\u003cli\u003eA Cloudflare account with a domain set up (e.g., \u003ccode\u003eyourdomain.com\u003c/code\u003e).\u003c/li\u003e\n\u003cli\u003eAlready created a linux bridge network in Proxmox for your VMs. Check out my blog post on \u003ca href=\"https://www.vijay-narayanan.com/posts/how-to-configure-dhcp-server-to-create-vmbr-bridge-network\"\u003eHow to Configure DHCP Server to Create vmbr Bridge Network\u003c/a\u003e for guidance.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"example-values-we-are-going-to-use\"\u003eExample values we are going to use\u003c/h2\u003e\n\u003cp\u003eAssuming you have a Proxmox VE installation with the following network configuration:\nNote that these values are examples. You should replace them with your actual network settings.\u003c/p\u003e","title":"Secure and Isolated Proxmox with Cloudflare Tunnel"},{"content":"Introduction This guide will help you set up a DHCP server on your Proxmox host to create a bridge network (vmbr1) for your virtual machines (VMs). This setup allows VMs to automatically receive IP addresses and network configuration from the DHCP server.\nAlso, helps in isolating the VM network while still providing internet access.\nInstall DHCP Server and Configure Bridge Network Install DHCP server on Proxmox host:\napt install isc-dhcp-server Set interface in /etc/default/isc-dhcp-server:\nINTERFACESv4=\u0026#34;vmbr1\u0026#34; Configure DHCP in /etc/dhcp/dhcpd.conf:\n# dhcpd.conf default-lease-time 600; max-lease-time 7200; authoritative; subnet 10.10.10.0 netmask 255.255.255.0 { range 10.10.10.50 10.10.10.100; option routers 10.10.10.1; option domain-name-servers 1.1.1.1, 8.8.8.8; } Configuration Breakdown:\nConfiguration Option Description subnet 10.10.10.0 netmask 255.255.255.0 { ... } Defines a DHCP scope for the 10.10.10.0/24 network. range 10.10.10.50 10.10.10.100; Specifies the pool of IP addresses to assign to clients. option routers 10.10.10.1; Sets the default gateway for DHCP clients. option domain-name-servers 1.1.1.1, 8.8.8.8; Specifies DNS servers for DHCP clients. 1.1.1.1 is Cloudflare\u0026rsquo;s DNS, and 8.8.8.8 is Google\u0026rsquo;s DNS. Start the service:\nsystemctl restart isc-dhcp-server systemctl status isc-dhcp-server Then reboot your VM or run:\nsudo dhclient eth0 Conclusion This setup allows your VMs to automatically receive IP addresses from the DHCP server configured on vmbr1. The DHCP server will assign IPs within the specified range, set the default gateway, and provide DNS servers for name resolution.\n","permalink":"http://localhost:1313/posts/proxmox/how-to-configure-dhcp-server-to-create-vmbr-bridge-network/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThis guide will help you set up a DHCP server on your Proxmox host to create a bridge network (\u003ccode\u003evmbr1\u003c/code\u003e) for your virtual machines (VMs). This setup allows VMs to automatically receive IP addresses and network configuration from the DHCP server.\u003c/p\u003e\n\u003cp\u003eAlso, helps in isolating the VM network while still providing internet access.\u003c/p\u003e\n\u003ch2 id=\"install-dhcp-server-and-configure-bridge-network\"\u003eInstall DHCP Server and Configure Bridge Network\u003c/h2\u003e\n\u003cp\u003eInstall DHCP server on Proxmox host:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eapt install isc-dhcp-server\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eSet interface in \u003ccode\u003e/etc/default/isc-dhcp-server\u003c/code\u003e:\u003c/p\u003e","title":"How to Configure DHCP Server to Create vmbr Bridge Network"}]